> S3 Automatically scales to high request rates and maintains a latency of 100 - 200 ms to get first byte out of S3

> We can achieve at least a **3,500 Write or 5,500 Read requests per second *per prefix*** in a bucket

No limit to the number of prefixes in our bucket

Suppose we have 4 prefixes in our S3 bucket. 
1. /folder1/sub1/
2. /folder1/sub2/
3. /1/
4. /2/

Since each prefix can serve 5,500 Read requests per second, if we spread read requests across all 4 prefixes uniformly, we can achieve a rate of **22,000 reads / second** in our system.!! GET ? HEAD

### Optimizing S3 performance

####  **Multi Part Upload** 
> Must be used for files over 5GB and **recommended for files over 100 MB** - Helps parallelize uploads to speed up transfers![[Screenshot 2024-04-28 at 12.57.12 PM.png]]


#### S3 Transfer Acceleration

> Increase transfer speed by **transferring file to an AWS edge location** which will **forward data to the S3 bucket** in the target region. 

Minimize the amount of public network and maximize private network access

> Compatible with Multi-part upload![[Screenshot 2024-04-28 at 12.59.27 PM.png]]

#### S3 Download Acceleration

> Parallelize GETs by requesting specific byte ranges . This increases resiliency in case of failures.

These requests can be made in parallel and thereby help speed up downloads:![[Screenshot 2024-04-28 at 1.03.40 PM.png]]

If we just want to get the file header details, we can use a **Byte range** request to S3 and we will just get the header information very quickly instead of the whole file:  ![[Screenshot 2024-04-28 at 1.04.40 PM.png]]




