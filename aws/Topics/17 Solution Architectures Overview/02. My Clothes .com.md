- My clothes.com is an online shopping store which has a shopping cart
- We have hundreds of users at the same time 
- We need to scale, maintain horizontal scalability and keep our web application-web tier as stateless as possible
- Users should not lose their shopping cart while navigating our website and even if there is downtime

#### Current Architecture 

This is the current state of our application architecture.
![[Screenshot 2024-04-15 at 12.50.57 AM.png]]

We have multiple EC2 instances that store data locally since we haven't configured a database. 

#### Users lose their shopping cart when moving to another instance

Since our application is load balanced and traffic is routed to multiple instances across AZs, when a user refreshes the website or logs back in again, there is a chance that they might lose access to their shopping cart because the request was directed to another instance.  The current architecture is not meant for stateful applications since each instance has it's own local state. 

#### Session affinity

Now we introduce stickiness and session affinity into the elastic load balancer - by doing this we can ensure that every request from a given user always goes to the same EC2 instance. This way users don't lose any of their session data. And the shopping cart is always available. 

![[Screenshot 2024-04-15 at 12.56.17 AM.png]]
But what happens when the particular EC2 instance is terminated because of the autoscaling group scaling down as less users start using our application ?

What is the next simplest approach ? Using cookies. 

#### Web cookies

Now since the EC2 instance storing data locally is a problem, we move each user's data to cookies, so now, instead the application state is defined by the cookie that the user passes along with each request.

![[Screenshot 2024-04-15 at 12.59.45 AM.png]]But what happens if the cookies are lost or damaged or corrupted ? 
This gives the user's power over defining what the shopping cart looks like, this can lead to so many problems!

**Also a cookie must be less than 4kb**. Requests can become slow, cookie validation logic must be implemented and we have to think about ways attackers don't get to modify this cookie in flight ( Probably SSL encryption can help here ).

Also we can't send large amounts of data through cookies, so if the client has to maintain state of shopping cart all the time, they will have to do a lot of server side logic on their end, which sounds stupid to me!

#### Server Sessions

Now to offload this state management from the client, we introduce a highly available cache to our backend architecture and allow users to pass a `session_id` along with each request. 

![[Screenshot 2024-04-15 at 1.05.10 AM.png]]

This way the data sent over network becomes just the `session_id` along with the action that needs to be performed. And the server (EC2 instance) can now handle the business logic after retrieving each user's `session_data` using the `session_id` form either ElastiCache or DynamoDB. 

**Note** : Elasticache offers sub milli second latency

This is a much more secure architecture, because attackers no longer have access to the data, all we have is just the session id and the action that is to be performed that is in transit. However I see a potential issue when the `session_id` that is sent to the server is tampered with. This was other's user's data can be modified. To avoid this we will have to introduce authentication to ensure the right user sends the right session id that is allocated to them. 

### Storing data in a database and scaling reads

Further we would like to store user data on the backend so there is lesser data involved as part of the requests - they just contain a security token and the action to be performed on the resource available to them.  ![[Screenshot 2024-04-15 at 1.12.29 AM.png]]

Further we can also set up Read Replicas so that if there are more users who want to fetch details about available products, we are able to serve it without impacting the write performance.  

#### Lazy Loading

To further enhance read performance we can use the concept of lazy loading on the server side. The server first looks into our cache to see if the required data is present if not, it fetches it from the Database and the loads it into the cache for subsequent requests that need that data. To maintain consistency, caches must be invalidated from time to time to ensure the most up to date data is available in the cache. 

This reduces CPU usage on RDS but shifts the responsibility of cache management to the server which is still fine.

![[Screenshot 2024-04-15 at 1.27.11 AM.png]]

**Surviving Disasters:** We can further go a step ahead and update both our Elasticache and the RDS server to be multi AZ so that we can be sure that our instances won't go down if any one data center faces outages or issues. 

**Security :** To ensure our application remains secure we create security groups for each of these resources and we restrict incoming traffic only from defined sources. 
1. Allow all traffic from the internet to our load balancer
2. Only allow traffic from our load balancer to our EC2 isntances
3. Only allow traffic from our EC2 instances to the ElastiCache cluster and the RDS cluster

### Summary

![[Screenshot 2024-04-15 at 1.32.19 AM.png]]